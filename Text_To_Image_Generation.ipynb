{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from IPython.utils import capture\n",
        "from IPython.display import clear_output\n",
        "\n",
        "print(\"\u001b[1;32mStarting...\")\n",
        "\n",
        "%pip install -U --pre xformers\n",
        "%pip install -U --pre triton\n",
        "%pip install diffusers accelerate transformers scipy safetensors\n",
        "%pip install gradio\n",
        "\n",
        "clear_output()\n",
        "\n",
        "print(\"\u001b[1;32mDone.\")"
      ],
      "metadata": {
        "id": "GWRM_f2Ygsit"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "import torch\n",
        "import numpy as np\n",
        "import gradio as gr\n",
        "from diffusers import (\n",
        "    UnCLIPPipeline,\n",
        "    StableDiffusionUpscalePipeline,\n",
        "    DDIMScheduler,\n",
        "    LMSDiscreteScheduler,\n",
        "    EulerDiscreteScheduler,\n",
        ")\n",
        "\n",
        "\n",
        "def make_pipeline_generator():\n",
        "    \"\"\"Create Karlo pipeline\"\"\"\n",
        "    pipe = UnCLIPPipeline.from_pretrained(\n",
        "        \"kakaobrain/karlo-v1-alpha\",\n",
        "        torch_dtype=torch.float16,\n",
        "    )\n",
        "    pipe = pipe.to(\"cuda\")\n",
        "    pipe.enable_attention_slicing()\n",
        "    return pipe\n",
        "\n",
        "\n",
        "def make_pipeline_upscaler(scheduler):\n",
        "    \"\"\"Create Stable-Diffusion upscaler pipeline with scpecified scheduler\"\"\"\n",
        "    if scheduler == \"Euler\":\n",
        "        scheduler = EulerDiscreteScheduler.from_pretrained(\n",
        "            \"stabilityai/stable-diffusion-x4-upscaler\", subfolder=\"scheduler\"\n",
        "        )\n",
        "    elif scheduler == \"LMS\":\n",
        "        scheduler = LMSDiscreteScheduler.from_pretrained(\n",
        "            \"stabilityai/stable-diffusion-x4-upscaler\", subfolder=\"scheduler\"\n",
        "        )\n",
        "    else:\n",
        "        scheduler = DDIMScheduler.from_pretrained(\n",
        "            \"stabilityai/stable-diffusion-x4-upscaler\", subfolder=\"scheduler\"\n",
        "        )\n",
        "\n",
        "    pipe = StableDiffusionUpscalePipeline.from_pretrained(\n",
        "        \"stabilityai/stable-diffusion-x4-upscaler\",\n",
        "        scheduler=scheduler,\n",
        "        torch_dtype=torch.float16,\n",
        "    )\n",
        "    pipe = pipe.to(\"cuda\")\n",
        "    pipe.set_use_memory_efficient_attention_xformers(True)\n",
        "    pipe.enable_attention_slicing()\n",
        "    return pipe\n",
        "\n",
        "\n",
        "def generate(prompt, n_images, n_prior, n_decoder, n_super_res, cfg_prior, cfg_decoder):\n",
        "    \"\"\"Generate image using the Karlo model\"\"\"\n",
        "    pipe = karlo_pipe\n",
        "    torch.cuda.empty_cache()\n",
        "    images = pipe(\n",
        "        prompt=prompt,\n",
        "        num_images_per_prompt=n_images,\n",
        "        prior_num_inference_steps=n_prior,\n",
        "        decoder_num_inference_steps=n_decoder,\n",
        "        super_res_num_inference_steps=n_super_res,\n",
        "        prior_guidance_scale=cfg_prior,\n",
        "        decoder_guidance_scale=cfg_decoder,\n",
        "    ).images\n",
        "    return images\n",
        "\n",
        "\n",
        "def upscale(scheduler, prompt, neg_prompt, images, n_steps, cfg):\n",
        "    \"\"\"Upscale image using the Stable-Diffusion upscaling model\"\"\"\n",
        "    batch_prompt = [prompt] * len(images)\n",
        "    batch_neg_prompt = [neg_prompt] * len(images)\n",
        "\n",
        "    pipe = up_pipe if scheduler==\"DDIM\" else make_pipeline_upscaler(scheduler)\n",
        "    torch.cuda.empty_cache()\n",
        "    images = pipe(\n",
        "        image=images,\n",
        "        prompt=batch_prompt,\n",
        "        negative_prompt=batch_neg_prompt,\n",
        "        num_inference_steps=n_steps,\n",
        "        guidance_scale=cfg,\n",
        "    ).images\n",
        "    return images\n",
        "\n",
        "\n",
        "def run(\n",
        "    prompt,\n",
        "    n_images,\n",
        "    up,\n",
        "    n_prior,\n",
        "    n_decoder,\n",
        "    n_super_res,\n",
        "    cfg_prior,\n",
        "    cfg_decoder,\n",
        "    up_prompt,\n",
        "    up_neg_prompt,\n",
        "    up_n_steps,\n",
        "    up_cfg,\n",
        "    up_scheduler,\n",
        "    show_original,\n",
        "    progress=gr.Progress(track_tqdm=True)\n",
        "):\n",
        "    images = generate(\n",
        "        prompt=prompt,\n",
        "        n_images=n_images,\n",
        "        n_prior=n_prior,\n",
        "        n_decoder=n_decoder,\n",
        "        n_super_res=n_super_res,\n",
        "        cfg_prior=cfg_prior,\n",
        "        cfg_decoder=cfg_decoder,\n",
        "    )\n",
        "\n",
        "    if up:\n",
        "        images_up = upscale(\n",
        "            scheduler=up_scheduler,\n",
        "            prompt=up_prompt if up_prompt else prompt,\n",
        "            neg_prompt=up_neg_prompt,\n",
        "            images=images,\n",
        "            n_steps=up_n_steps,\n",
        "            cfg=up_cfg,\n",
        "        )\n",
        "        if show_original:\n",
        "            concat = list(images_up) + list(images)\n",
        "            return concat\n",
        "        else:\n",
        "            return images_up\n",
        "\n",
        "    return images\n",
        "\n",
        "# Set up and download pipelines\n",
        "print(\"\u001b[1;32mDownloading models...\")\n",
        "karlo_pipe = make_pipeline_generator()\n",
        "up_pipe = make_pipeline_upscaler(\"DDIM\")\n",
        "clear_output()\n",
        "print(\"\u001b[1;32mDone.\")"
      ],
      "metadata": {
        "id": "ZEHeP6Mqhfs5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with gr.Blocks() as app:\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=1):\n",
        "            gr.Markdown(\"# stable-karlo üñºÔ∏è\")\n",
        "            prompt = gr.Textbox(\n",
        "                label=\"Prompt (77 words max)\",\n",
        "                interactive=True,\n",
        "                value=\"A photo of a shiba inu wearing a stylish red scarf, high quality.\",\n",
        "            )\n",
        "            n_images = gr.Slider(\n",
        "                label=\"Number of images\",\n",
        "                interactive=True,\n",
        "                value=1,\n",
        "                minimum=0,\n",
        "                maximum=8,\n",
        "                step=1,\n",
        "            )\n",
        "            up = gr.Checkbox(\n",
        "                label=\"Upscale with Stable-Diffusion\", interactive=True, value=True\n",
        "            )\n",
        "\n",
        "            with gr.Accordion(\"Karlo Settings\", open=False):\n",
        "                n_prior = gr.Slider(\n",
        "                    label=\"Number of prior steps\",\n",
        "                    interactive=True,\n",
        "                    minimum=0,\n",
        "                    maximum=100,\n",
        "                    step=1,\n",
        "                    value=25,\n",
        "                )\n",
        "                n_decoder = gr.Slider(\n",
        "                    label=\"Number of decoder steps\",\n",
        "                    interactive=True,\n",
        "                    minimum=0,\n",
        "                    maximum=100,\n",
        "                    step=1,\n",
        "                    value=25,\n",
        "                )\n",
        "                n_super_res = gr.Slider(\n",
        "                    label=\"Number of super res steps\",\n",
        "                    interactive=True,\n",
        "                    minimum=0,\n",
        "                    maximum=100,\n",
        "                    step=1,\n",
        "                    value=7,\n",
        "                )\n",
        "                cfg_prior = gr.Slider(\n",
        "                    label=\"Prior guidance scale\",\n",
        "                    interactive=True,\n",
        "                    minimum=0.0,\n",
        "                    maximum=20.0,\n",
        "                    step=0.1,\n",
        "                    value=4.0,\n",
        "                )\n",
        "                cfg_decoder = gr.Slider(\n",
        "                    label=\"Decoder guidance scale\",\n",
        "                    interactive=True,\n",
        "                    minimum=0.0,\n",
        "                    maximum=20.0,\n",
        "                    step=0.1,\n",
        "                    value=4.0,\n",
        "                )\n",
        "\n",
        "            with gr.Accordion(\"Stable-Diffusion Settings\", open=False):\n",
        "                up_prompt = gr.Textbox(\n",
        "                    label=\"Prompt\", placeholder=\"Leave blank to use Karlo prompt\"\n",
        "                )\n",
        "                up_neg_prompt = gr.Textbox(label=\"Negative prompt\")\n",
        "                up_n_steps = gr.Slider(\n",
        "                    label=\"Number of steps\",\n",
        "                    interactive=True,\n",
        "                    minimum=0,\n",
        "                    maximum=200,\n",
        "                    step=1,\n",
        "                    value=35,\n",
        "                )\n",
        "                up_cfg = gr.Slider(\n",
        "                    label=\"Guidance scale\",\n",
        "                    interactive=True,\n",
        "                    minimum=1.01,\n",
        "                    maximum=20.0,\n",
        "                    step=0.1,\n",
        "                    value=7.5,\n",
        "                )\n",
        "                up_scheduler = gr.Radio(\n",
        "                    label=\"Scheduler\",\n",
        "                    choices=[\"DDIM\", \"LMS\", \"Euler\"],\n",
        "                    interactive=True,\n",
        "                    value=\"DDIM\",\n",
        "                )\n",
        "                show_original = gr.Checkbox(\n",
        "                    label=\"Show original images\", interactive=True, value=False\n",
        "                )\n",
        "\n",
        "            btn = gr.Button(\"Generate\")\n",
        "\n",
        "        with gr.Column(scale=2):\n",
        "            gallery = gr.Gallery(label=\"Output\", show_label=False).style(grid=4)\n",
        "\n",
        "        btn.click(\n",
        "            fn=run,\n",
        "            inputs=[\n",
        "                prompt,\n",
        "                n_images,\n",
        "                up,\n",
        "                n_prior,\n",
        "                n_decoder,\n",
        "                n_super_res,\n",
        "                cfg_prior,\n",
        "                cfg_decoder,\n",
        "                up_prompt,\n",
        "                up_neg_prompt,\n",
        "                up_n_steps,\n",
        "                up_cfg,\n",
        "                up_scheduler,\n",
        "                show_original,\n",
        "            ],\n",
        "            outputs=gallery,\n",
        "        )\n",
        "\n",
        "app.queue().launch(quiet=True, height=600)"
      ],
      "metadata": {
        "id": "A8yq52axMg4k"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}